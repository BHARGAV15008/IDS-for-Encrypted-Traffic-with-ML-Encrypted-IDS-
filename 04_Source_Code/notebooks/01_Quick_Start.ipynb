{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P22 IDS - Quick Start Notebook\n",
    "\n",
    "This notebook demonstrates basic usage of the Encrypted Traffic IDS.\n",
    "\n",
    "## What You'll Learn:\n",
    "1. Initialize the IDS system\n",
    "2. Process CSV files\n",
    "3. Process PCAP files\n",
    "4. Run predictions with LSTM and CNN\n",
    "5. View and interpret results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent directory to path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "# Import required modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from orchestrator import ServiceOrchestrator\n",
    "from services.dataIngestionService import DataIngestionService\n",
    "from services.lstmModelService import LSTMModelService\n",
    "from services.cnnModelService import CNNModelService\n",
    "from services.outputManagementService import OutputManagementService\n",
    "\n",
    "print(\"✓ Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize the IDS System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize orchestrator\n",
    "orchestrator = ServiceOrchestrator('../config.example.yaml')\n",
    "\n",
    "# Start all services\n",
    "if orchestrator.initialize():\n",
    "    print(\"✓ All services initialized successfully!\")\n",
    "else:\n",
    "    print(\"✗ Failed to initialize services\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check system status\n",
    "status = orchestrator.getSystemStatus()\n",
    "\n",
    "print(\"\\nSystem Status:\")\n",
    "print(f\"Initialized: {status['initialized']}\")\n",
    "print(\"\\nService Status:\")\n",
    "for service_name, service_info in status['services'].items():\n",
    "    print(f\"  {service_name}: {service_info.get('status')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process CSV File\n",
    "\n",
    "Replace `'sample_data.csv'` with your actual CSV file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Create dummy CSV data for testing\n",
    "# Skip this if you have real data\n",
    "\n",
    "dummy_data = pd.DataFrame({\n",
    "    'feature1': np.random.rand(100),\n",
    "    'feature2': np.random.rand(100),\n",
    "    'feature3': np.random.rand(100),\n",
    "    'feature4': np.random.rand(100),\n",
    "    'feature5': np.random.rand(100),\n",
    "    'label': np.random.randint(0, 2, 100)\n",
    "})\n",
    "\n",
    "dummy_data.to_csv('../sample_data.csv', index=False)\n",
    "print(\"✓ Created sample CSV file: sample_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process CSV file\n",
    "csv_file = '../sample_data.csv'\n",
    "\n",
    "print(f\"Processing CSV file: {csv_file}\")\n",
    "csv_result = orchestrator.processDataFile(csv_file, fileType='csv')\n",
    "\n",
    "print(f\"\\n✓ CSV Processing Complete!\")\n",
    "print(f\"  File Type: {csv_result['fileType']}\")\n",
    "print(f\"  Samples: {csv_result['sampleCount']}\")\n",
    "print(f\"  Features: {len(csv_result['featureNames'])}\")\n",
    "print(f\"  Feature Shape: {csv_result['features'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Predictions on CSV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference with both models\n",
    "print(\"Running LSTM and CNN models...\")\n",
    "\n",
    "prediction_result = orchestrator.runInference(\n",
    "    data=csv_result,\n",
    "    modelType='both',\n",
    "    aggregate=True\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Prediction Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "print(\"=== Final Prediction Results ===\")\n",
    "print(f\"Model Type: {prediction_result['modelType']}\")\n",
    "print(f\"Aggregation Method: {prediction_result.get('aggregationMethod', 'N/A')}\")\n",
    "print(f\"\\nPredictions: {prediction_result['predictions'][:10]}...\")\n",
    "print(f\"Confidence: {prediction_result['confidence']:.4f}\")\n",
    "\n",
    "# Count predictions by class\n",
    "from collections import Counter\n",
    "pred_counts = Counter(prediction_result['predictions'])\n",
    "print(f\"\\nPrediction Distribution:\")\n",
    "for class_id, count in sorted(pred_counts.items()):\n",
    "    print(f\"  Class {class_id}: {count} samples ({count/len(prediction_result['predictions'])*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare LSTM vs CNN Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run LSTM only\n",
    "lstm_result = orchestrator.runInference(\n",
    "    data=csv_result,\n",
    "    modelType='lstm',\n",
    "    aggregate=False\n",
    ")\n",
    "\n",
    "# Run CNN only\n",
    "cnn_result = orchestrator.runInference(\n",
    "    data=csv_result,\n",
    "    modelType='cnn',\n",
    "    aggregate=False\n",
    ")\n",
    "\n",
    "print(\"=== Model Comparison ===\")\n",
    "print(f\"\\nLSTM Model:\")\n",
    "print(f\"  Predictions: {lstm_result['predictions'][:10]}...\")\n",
    "print(f\"  Avg Confidence: {np.mean(lstm_result['confidences']):.4f}\")\n",
    "\n",
    "print(f\"\\nCNN Model:\")\n",
    "print(f\"  Predictions: {cnn_result['predictions'][:10]}...\")\n",
    "print(f\"  Avg Confidence: {np.mean(cnn_result['confidences']):.4f}\")\n",
    "\n",
    "# Calculate agreement\n",
    "agreement = sum(1 for l, c in zip(lstm_result['predictions'], cnn_result['predictions']) if l == c)\n",
    "print(f\"\\nModel Agreement: {agreement}/{len(lstm_result['predictions'])} ({agreement/len(lstm_result['predictions'])*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot prediction distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# LSTM predictions\n",
    "axes[0].hist(lstm_result['predictions'], bins=10, alpha=0.7, color='blue')\n",
    "axes[0].set_title('LSTM Predictions')\n",
    "axes[0].set_xlabel('Class')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "# CNN predictions\n",
    "axes[1].hist(cnn_result['predictions'], bins=10, alpha=0.7, color='green')\n",
    "axes[1].set_title('CNN Predictions')\n",
    "axes[1].set_xlabel('Class')\n",
    "axes[1].set_ylabel('Count')\n",
    "\n",
    "# Ensemble predictions\n",
    "axes[2].hist(prediction_result['predictions'], bins=10, alpha=0.7, color='red')\n",
    "axes[2].set_title('Ensemble Predictions')\n",
    "axes[2].set_xlabel('Class')\n",
    "axes[2].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confidence scores\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# LSTM confidence distribution\n",
    "axes[0].hist(lstm_result['confidences'], bins=20, alpha=0.7, color='blue', edgecolor='black')\n",
    "axes[0].axvline(np.mean(lstm_result['confidences']), color='red', linestyle='--', \n",
    "                label=f\"Mean: {np.mean(lstm_result['confidences']):.3f}\")\n",
    "axes[0].set_title('LSTM Confidence Distribution')\n",
    "axes[0].set_xlabel('Confidence')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].legend()\n",
    "\n",
    "# CNN confidence distribution\n",
    "axes[1].hist(cnn_result['confidences'], bins=20, alpha=0.7, color='green', edgecolor='black')\n",
    "axes[1].axvline(np.mean(cnn_result['confidences']), color='red', linestyle='--',\n",
    "                label=f\"Mean: {np.mean(cnn_result['confidences']):.3f}\")\n",
    "axes[1].set_title('CNN Confidence Distribution')\n",
    "axes[1].set_xlabel('Confidence')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. View Output Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List output files\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path('../outputs')\n",
    "\n",
    "print(\"=== Output Files ===\")\n",
    "for subdir in ['lstm', 'cnn', 'final']:\n",
    "    dir_path = output_dir / subdir\n",
    "    if dir_path.exists():\n",
    "        files = list(dir_path.glob('*.json'))\n",
    "        print(f\"\\n{subdir.upper()}/: {len(files)} files\")\n",
    "        if files:\n",
    "            print(f\"  Latest: {files[-1].name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and display a final prediction file\n",
    "final_files = list((output_dir / 'final').glob('final_prediction_*.json'))\n",
    "if final_files:\n",
    "    latest_file = final_files[-1]\n",
    "    print(f\"Reading: {latest_file.name}\")\n",
    "    \n",
    "    with open(latest_file) as f:\n",
    "        final_data = json.load(f)\n",
    "    \n",
    "    print(\"\\n=== Final Prediction File ===\")\n",
    "    print(json.dumps(final_data, indent=2)[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate output report\n",
    "report = orchestrator.outputService.generateReport()\n",
    "\n",
    "print(\"=== Output Report ===\")\n",
    "print(f\"Generated At: {report['generatedAt']}\")\n",
    "print(f\"\\nOutput Counts:\")\n",
    "for output_type, count in report['outputCounts'].items():\n",
    "    print(f\"  {output_type.upper()}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shutdown all services\n",
    "orchestrator.shutdown()\n",
    "print(\"✓ All services shut down successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned how to:\n",
    "1. ✓ Initialize the IDS system\n",
    "2. ✓ Process CSV files\n",
    "3. ✓ Run predictions with LSTM and CNN models\n",
    "4. ✓ Compare model outputs\n",
    "5. ✓ Visualize results\n",
    "6. ✓ Access output files\n",
    "7. ✓ Generate reports\n",
    "\n",
    "**Next Steps:**\n",
    "- Try with your own CSV files\n",
    "- Explore PCAP processing in the next notebook\n",
    "- Learn about model training and hyperparameter tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
