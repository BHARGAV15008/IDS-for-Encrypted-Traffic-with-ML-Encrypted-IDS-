{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P22 IDS - PCAP Processing Notebook\n",
    "\n",
    "This notebook demonstrates how to process PCAP files (packet captures).\n",
    "\n",
    "## What You'll Learn:\n",
    "1. Load and process PCAP files\n",
    "2. Extract packet features\n",
    "3. Analyze packet metadata\n",
    "4. Run threat detection on packets\n",
    "5. Visualize packet-level analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "from orchestrator import ServiceOrchestrator\n",
    "from services.dataIngestionService import DataIngestionService\n",
    "\n",
    "# Check if Scapy is available\n",
    "try:\n",
    "    import scapy.all as scapy\n",
    "    print(\"✓ Scapy is available\")\n",
    "except ImportError:\n",
    "    print(\"⚠ Scapy not installed. Install with: pip install scapy\")\n",
    "\n",
    "print(\"✓ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Sample PCAP File (Optional)\n",
    "\n",
    "Skip this if you have a real PCAP file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample PCAP file with synthetic packets\n",
    "try:\n",
    "    from scapy.all import IP, TCP, UDP, Ether, wrpcap\n",
    "    \n",
    "    packets = []\n",
    "    \n",
    "    # Create 50 TCP packets\n",
    "    for i in range(50):\n",
    "        pkt = Ether() / IP(src=f\"192.168.1.{i%10}\", dst=f\"10.0.0.{i%5}\") / \\\n",
    "              TCP(sport=1024+i, dport=80) / (f\"Sample payload {i}\" * 10)\n",
    "        packets.append(pkt)\n",
    "    \n",
    "    # Create 30 UDP packets\n",
    "    for i in range(30):\n",
    "        pkt = Ether() / IP(src=f\"192.168.1.{i%10}\", dst=f\"10.0.0.{i%5}\") / \\\n",
    "              UDP(sport=5000+i, dport=53) / (f\"DNS query {i}\" * 5)\n",
    "        packets.append(pkt)\n",
    "    \n",
    "    # Save to file\n",
    "    wrpcap('../sample_capture.pcap', packets)\n",
    "    print(f\"✓ Created sample PCAP file with {len(packets)} packets\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not create sample PCAP: {e}\")\n",
    "    print(\"Please provide your own PCAP file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize IDS System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize orchestrator\n",
    "orchestrator = ServiceOrchestrator('../config.example.yaml')\n",
    "\n",
    "if orchestrator.initialize():\n",
    "    print(\"✓ Services initialized!\")\n",
    "    \n",
    "    # Check status\n",
    "    status = orchestrator.getSystemStatus()\n",
    "    for name, info in status['services'].items():\n",
    "        print(f\"  {name}: {info['status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Process PCAP File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process PCAP file\n",
    "pcap_file = '../sample_capture.pcap'  # Change to your PCAP file\n",
    "\n",
    "print(f\"Processing PCAP file: {pcap_file}\")\n",
    "pcap_result = orchestrator.processDataFile(pcap_file, fileType='pcap')\n",
    "\n",
    "print(f\"\\n✓ PCAP Processing Complete!\")\n",
    "print(f\"  File Type: {pcap_result['fileType']}\")\n",
    "print(f\"  Packets: {pcap_result['packetCount']}\")\n",
    "print(f\"  Feature Shape: {pcap_result['features'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Packet Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metadata\n",
    "metadata = pcap_result['metadata']\n",
    "\n",
    "# Create DataFrame for easier analysis\n",
    "metadata_df = pd.DataFrame(metadata)\n",
    "\n",
    "print(\"=== Packet Metadata ===\")\n",
    "print(metadata_df.head(10))\n",
    "\n",
    "print(f\"\\nTotal Packets: {len(metadata_df)}\")\n",
    "print(f\"Unique Source IPs: {metadata_df['srcIP'].nunique()}\")\n",
    "print(f\"Unique Dest IPs: {metadata_df['dstIP'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protocol distribution\n",
    "protocol_counts = Counter(metadata_df['protocol'].dropna())\n",
    "\n",
    "print(\"\\n=== Protocol Distribution ===\")\n",
    "for protocol, count in protocol_counts.items():\n",
    "    print(f\"{protocol}: {count} packets ({count/len(metadata_df)*100:.1f}%)\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(protocol_counts.keys(), protocol_counts.values(), color='steelblue')\n",
    "plt.title('Protocol Distribution')\n",
    "plt.xlabel('Protocol')\n",
    "plt.ylabel('Packet Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packet size distribution\n",
    "packet_sizes = metadata_df['length'].dropna()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(packet_sizes, bins=30, color='lightcoral', edgecolor='black')\n",
    "plt.title('Packet Size Distribution')\n",
    "plt.xlabel('Size (bytes)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(packet_sizes)\n",
    "plt.title('Packet Size Box Plot')\n",
    "plt.ylabel('Size (bytes)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average Packet Size: {packet_sizes.mean():.2f} bytes\")\n",
    "print(f\"Median Packet Size: {packet_sizes.median():.2f} bytes\")\n",
    "print(f\"Min/Max: {packet_sizes.min():.0f} / {packet_sizes.max():.0f} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Threat Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run detection with both models\n",
    "print(\"Running threat detection...\")\n",
    "\n",
    "detection_result = orchestrator.runInference(\n",
    "    data=pcap_result,\n",
    "    modelType='both',\n",
    "    aggregate=True\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Detection Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display detection results\n",
    "print(\"=== Threat Detection Results ===\")\n",
    "print(f\"Model: {detection_result['modelType']}\")\n",
    "print(f\"Aggregation: {detection_result.get('aggregationMethod', 'N/A')}\")\n",
    "print(f\"Confidence: {detection_result['confidence']:.4f}\")\n",
    "\n",
    "# Count threats\n",
    "predictions = detection_result['predictions']\n",
    "threats = sum(1 for p in predictions if p != 0)\n",
    "\n",
    "print(f\"\\nThreat Summary:\")\n",
    "print(f\"  Total Packets Analyzed: {len(predictions)}\")\n",
    "print(f\"  Normal Traffic: {len(predictions) - threats}\")\n",
    "print(f\"  Threats Detected: {threats}\")\n",
    "print(f\"  Threat Rate: {threats/len(predictions)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Detection Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions over time\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(predictions, 'o-', markersize=3, alpha=0.6)\n",
    "plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.5, label='Threat Threshold')\n",
    "plt.title('Predictions Over Packets')\n",
    "plt.xlabel('Packet Index')\n",
    "plt.ylabel('Prediction (0=Normal, 1+=Threat)')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "pred_counts = Counter(predictions)\n",
    "plt.bar(pred_counts.keys(), pred_counts.values(), color='orange', edgecolor='black')\n",
    "plt.title('Prediction Distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify suspicious packets\n",
    "threat_indices = [i for i, p in enumerate(predictions) if p != 0]\n",
    "\n",
    "if threat_indices:\n",
    "    print(f\"\\n=== Suspicious Packets (First 10) ===\")\n",
    "    threat_metadata = metadata_df.iloc[threat_indices[:10]]\n",
    "    print(threat_metadata[['srcIP', 'dstIP', 'srcPort', 'dstPort', 'protocol', 'length']])\n",
    "else:\n",
    "    print(\"\\n✓ No threats detected - all traffic appears normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compare LSTM vs CNN for PCAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run models separately\n",
    "lstm_result = orchestrator.runInference(pcap_result, 'lstm', False)\n",
    "cnn_result = orchestrator.runInference(pcap_result, 'cnn', False)\n",
    "\n",
    "print(\"=== Model Comparison ===\")\n",
    "print(f\"\\nLSTM (Temporal Analysis):\")\n",
    "print(f\"  Threats Detected: {sum(1 for p in lstm_result['predictions'] if p != 0)}\")\n",
    "print(f\"  Avg Confidence: {np.mean(lstm_result['confidences']):.4f}\")\n",
    "\n",
    "print(f\"\\nCNN (Spatial/Packet Analysis):\")\n",
    "print(f\"  Threats Detected: {sum(1 for p in cnn_result['predictions'] if p != 0)}\")\n",
    "print(f\"  Avg Confidence: {np.mean(cnn_result['confidences']):.4f}\")\n",
    "\n",
    "# Calculate agreement\n",
    "agreement = sum(1 for l, c in zip(lstm_result['predictions'], cnn_result['predictions']) if l == c)\n",
    "print(f\"\\nModel Agreement: {agreement}/{len(predictions)} ({agreement/len(predictions)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# LSTM\n",
    "axes[0].plot(lstm_result['predictions'], 'b-', alpha=0.6, label='LSTM')\n",
    "axes[0].set_title('LSTM Predictions')\n",
    "axes[0].set_xlabel('Packet Index')\n",
    "axes[0].set_ylabel('Prediction')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# CNN\n",
    "axes[1].plot(cnn_result['predictions'], 'g-', alpha=0.6, label='CNN')\n",
    "axes[1].set_title('CNN Predictions')\n",
    "axes[1].set_xlabel('Packet Index')\n",
    "axes[1].set_ylabel('Prediction')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Both overlayed\n",
    "axes[2].plot(lstm_result['predictions'], 'b-', alpha=0.5, label='LSTM')\n",
    "axes[2].plot(cnn_result['predictions'], 'g-', alpha=0.5, label='CNN')\n",
    "axes[2].set_title('LSTM vs CNN')\n",
    "axes[2].set_xlabel('Packet Index')\n",
    "axes[2].set_ylabel('Prediction')\n",
    "axes[2].legend()\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Analysis Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create analysis report\n",
    "report = {\n",
    "    'file': pcap_file,\n",
    "    'timestamp': pd.Timestamp.now().isoformat(),\n",
    "    'packet_count': len(metadata_df),\n",
    "    'protocol_distribution': dict(protocol_counts),\n",
    "    'packet_size_stats': {\n",
    "        'mean': float(packet_sizes.mean()),\n",
    "        'median': float(packet_sizes.median()),\n",
    "        'min': int(packet_sizes.min()),\n",
    "        'max': int(packet_sizes.max())\n",
    "    },\n",
    "    'detection_results': {\n",
    "        'threats_detected': threats,\n",
    "        'threat_rate': float(threats/len(predictions)*100),\n",
    "        'confidence': float(detection_result['confidence'])\n",
    "    },\n",
    "    'model_comparison': {\n",
    "        'lstm_threats': int(sum(1 for p in lstm_result['predictions'] if p != 0)),\n",
    "        'cnn_threats': int(sum(1 for p in cnn_result['predictions'] if p != 0)),\n",
    "        'agreement_rate': float(agreement/len(predictions)*100)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save report\n",
    "report_file = '../pcap_analysis_report.json'\n",
    "with open(report_file, 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(f\"✓ Analysis report saved to: {report_file}\")\n",
    "print(\"\\n\" + json.dumps(report, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shutdown services\n",
    "orchestrator.shutdown()\n",
    "print(\"✓ Services shut down successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "1. ✓ How to process PCAP files\n",
    "2. ✓ Extract and analyze packet metadata\n",
    "3. ✓ Run threat detection on packet captures\n",
    "4. ✓ Compare LSTM vs CNN for packet analysis\n",
    "5. ✓ Visualize packet-level results\n",
    "6. ✓ Generate analysis reports\n",
    "\n",
    "**Key Insights:**\n",
    "- **CNN** is better at analyzing individual packet structures (spatial patterns)\n",
    "- **LSTM** is better at analyzing packet sequences (temporal patterns)\n",
    "- **Ensemble** combines both for robust detection\n",
    "\n",
    "**Next Steps:**\n",
    "- Try with real network captures\n",
    "- Experiment with different maxPackets settings\n",
    "- Learn about model training in the next notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
